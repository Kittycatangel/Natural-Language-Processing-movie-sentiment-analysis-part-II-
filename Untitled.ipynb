{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20d647e0",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Stop-words\" data-toc-modified-id=\"Stop-words-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Stop words</a></span><ul class=\"toc-item\"><li><span><a href=\"#Grid-search\" data-toc-modified-id=\"Grid-search-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Grid search</a></span></li></ul></li><li><span><a href=\"#Data-Rescaling\" data-toc-modified-id=\"Data-Rescaling-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Data Rescaling</a></span></li><li><span><a href=\"#Investigating-Model-Coefficients\" data-toc-modified-id=\"Investigating-Model-Coefficients-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Investigating Model Coefficients</a></span></li><li><span><a href=\"#Bag-of-Words-with-More-Than-One-Word-(n-Grams)\" data-toc-modified-id=\"Bag-of-Words-with-More-Than-One-Word-(n-Grams)-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Bag-of-Words with More Than One Word (n-Grams)</a></span></li><li><span><a href=\"#Heatmap\" data-toc-modified-id=\"Heatmap-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Heatmap</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf4c188",
   "metadata": {},
   "source": [
    "# Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b133929",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "print(\"Number of stop words: {}\".format(len(ENGLISH_STOP_WORDS)))\n",
    "print(\"Every 10th stopword:\\n{}\".format(list(ENGLISH_STOP_WORDS)[::10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ed2a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying stop_words=\"english\" uses the built-in list.\n",
    "# We could also augment it and pass our own.\n",
    "vect = CountVectorizer(min_df=5, stop_words=\"english\").fit(text_train)\n",
    "X_train = vect.transform(text_train)\n",
    "print(\"X_train with stop words:\\n{}\".format(repr(X_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf73e6fa",
   "metadata": {},
   "source": [
    "## Grid search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daee6036",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(LogisticRegression(), param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cfe536",
   "metadata": {},
   "source": [
    "# Data Rescaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d861f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "pipe = make_pipeline(TfidfVectorizer(min_df=5, norm=None),\n",
    "LogisticRegression())\n",
    "param_grid = {'logisticregression__C': [0.001, 0.01, 0.1, 1, 10]}\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5)\n",
    "grid.fit(text_train, y_train)\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb17409e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = grid.best_estimator_.named_steps[\"tfidfvectorizer\"]\n",
    "# transform the training dataset\n",
    "X_train = vectorizer.transform(text_train)\n",
    "# find maximum value for each of the features over the dataset\n",
    "max_value = X_train.max(axis=0).toarray().ravel()\n",
    "sorted_by_tfidf = max_value.argsort()\n",
    "# get feature names\n",
    "feature_names = np.array(vectorizer.get_feature_names())\n",
    "print(\"Features with lowest tfidf:\\n{}\".format(\n",
    "feature_names[sorted_by_tfidf[:20]]))\n",
    "print(\"Features with highest tfidf: \\n{}\".format(\n",
    "feature_names[sorted_by_tfidf[-20:]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99909ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_by_idf = np.argsort(vectorizer.idf_)\n",
    "print(\"Features with lowest idf:\\n{}\".format(\n",
    "feature_names[sorted_by_idf[:100]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5449b322",
   "metadata": {},
   "source": [
    "# Investigating Model Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27aaf9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mglearn.tools.visualize_coefficients(\n",
    "grid.best_estimator_.named_steps[\"logisticregression\"].coef_,\n",
    "feature_names, n_top_features=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb80969",
   "metadata": {},
   "source": [
    "# Bag-of-Words with More Than One Word (n-Grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577f07df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"bards_words:\\n{}\".format(bards_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9960e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range=(1, 1)).fit(bards_words)\n",
    "print(\"Vocabulary size: {}\".format(len(cv.vocabulary_)))\n",
    "print(\"Vocabulary:\\n{}\".format(cv.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6965d900",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range=(2, 2)).fit(bards_words)\n",
    "print(\"Vocabulary size: {}\".format(len(cv.vocabulary_)))\n",
    "print(\"Vocabulary:\\n{}\".format(cv.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7071e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Transformed data (dense):\\n{}\".format(cv.transform(bards_words).toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5955b16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range=(1, 3)).fit(bards_words)\n",
    "print(\"Vocabulary size: {}\".format(len(cv.vocabulary_)))\n",
    "print(\"Vocabulary:\\n{}\".format(cv.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e82e0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(TfidfVectorizer(min_df=5), LogisticRegression())\n",
    "# running the grid search takes a long time because of the\n",
    "# relatively large grid and the inclusion of trigrams\n",
    "param_grid = {\"logisticregression__C\": [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "\"tfidfvectorizer__ngram_range\": [(1, 1), (1, 2), (1, 3)]}\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5)\n",
    "grid.fit(text_train, y_train)\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(grid.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af743fa",
   "metadata": {},
   "source": [
    "# Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963560ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract scores from grid_search\n",
    "scores = grid.cv_results_['mean_test_score'].reshape(-1, 3).T\n",
    "# visualize heat map\n",
    "heatmap = mglearn.tools.heatmap(\n",
    "scores, xlabel=\"C\", ylabel=\"ngram_range\", cmap=\"viridis\", fmt=\"%.3f\",\n",
    "xticklabels=param_grid['logisticregression__C'],\n",
    "yticklabels=param_grid['tfidfvectorizer__ngram_range'])\n",
    "plt.colorbar(heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf648bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract feature names and coefficients\n",
    "vect = grid.best_estimator_.named_steps['tfidfvectorizer']\n",
    "feature_names = np.array(vect.get_feature_names())\n",
    "coef = grid.best_estimator_.named_steps['logisticregression'].coef_\n",
    "mglearn.tools.visualize_coefficients(coef, feature_names, n_top_features=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af116d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find 3-gram features\n",
    "mask = np.array([len(feature.split(\" \")) for feature in feature_names]) == 3\n",
    "# visualize only 3-gram features\n",
    "mglearn.tools.visualize_coefficients(coef.ravel()[mask],\n",
    "feature_names[mask], n_top_features=40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
